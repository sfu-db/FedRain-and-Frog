{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps, loads\n",
    "from time import time\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import py_stringmatching as sm\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow.losses import sigmoid_cross_entropy\n",
    "from tensorflow.python.ops.parallel_for import jacobian\n",
    "\n",
    "from mlsql.archiver import Record\n",
    "from mlsql.experiments.duti import create_gradient_model, create_dataset, create_influence_model, DogCatConfig\n",
    "from mlsql.tensorflow.problem import LogisticRegression as tfLogisticRegression\n",
    "from mlsql.tensorflow.utils import EarlyStopTrainer\n",
    "\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1558545695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_type = DogCatConfig.Duti\n",
    "query = \"SELECT COUNT(*) WHERE clf() = 1\"\n",
    "EXPERIMENT_NAME = \"DUTI-GD\"\n",
    "EXPERIMENT_DESC = {\n",
    "    \"seed\": seed,\n",
    "    \"query\": query,\n",
    "    \"dataset\": \"duti\",\n",
    "    \"corrupt_type\": str(corrupt_type),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain, ytrain), (Xtest, ytest), ycrptd, sel_crpt = create_dataset(seed, corrupt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xquery = Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_loss_func(Xquery, theta):\n",
    "    nquery = Xquery.shape[0].value\n",
    "    sum = tf.reduce_sum(tf.sigmoid(Xquery @ theta))\n",
    "    return 1 / nquery * tf.norm(ytest.sum() - sum)\n",
    "    \n",
    "(theta, delta, logistic_objective, total_loss), (train_delta_op, train_theta_op) = create_gradient_model(Xtrain, Xquery, ycrptd, query_loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6153e7aba77341b1b5cbc2f55ec284c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=200000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = skLogisticRegression(solver=\"lbfgs\", max_iter=500, random_state=seed).fit(Xtrain, ycrptd)\n",
    "clff1 = f1_score(ytest, clf.predict(Xtest))\n",
    "clfrecall = f1_score(ytest, clf.predict(Xtest))\n",
    "clfprecision = f1_score(ytest, clf.predict(Xtest))\n",
    "vdeltas = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in EarlyStopTrainer(sess, total_loss, max_iter=200000, tol=1e-6, tol_range=100, progress=\"Train\"):\n",
    "        for _ in EarlyStopTrainer(sess, logistic_objective, max_iter=1000, tol=1e-4):\n",
    "            sess.run(train_theta_op)\n",
    "        sess.run(train_delta_op)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            vdelta, vtheta = sess.run([delta, theta])\n",
    "            vdeltas.append(vdelta)\n",
    "vdeltas = np.asarray(vdeltas)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta = (1 - sel_crpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.25      0.33        36\n",
      "           1       0.67      0.86      0.75        64\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       100\n",
      "   macro avg       0.59      0.55      0.54       100\n",
      "weighted avg       0.61      0.64      0.60       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tdelta, vdeltas[-1,:] > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Record(EXPERIMENT_NAME)\n",
    "r.input(EXPERIMENT_DESC)\n",
    "r.output({\"model_perf\": [clff1, clfprecision, clfrecall], \"deltas\": vdeltas.tolist(), \"tdelta\": tdelta.tolist()})\n",
    "r.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249caf88b65545e2a9cfbd0ad4b225f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.Duti]', max=72, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7180e82984e9428da31e8ff790ef372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.FarLine]', max=20, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a6736ebbd42b195db0d589db1ef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.CloseBoundary]', max=20, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 1558545695\n",
    "EXPERIMENT_NAME = \"DUTI-Influence-Retrain\"\n",
    "query = \"SELECT COUNT(*) WHERE clf() = 1\"\n",
    "\n",
    "for corrupt_type in DogCatConfig:\n",
    "    EXPERIMENT_DESC = {\n",
    "        \"seed\": seed,\n",
    "        \"query\": query,\n",
    "        \"dataset\": \"duti\",\n",
    "        \"corrupt_type\": str(corrupt_type),\n",
    "    }\n",
    "\n",
    "    desc = f\"[{corrupt_type}]\"\n",
    "\n",
    "    (Xtrain, ytrain), (Xtest, ytest), ycrptd, sel_crpt = create_dataset(seed, corrupt_type)\n",
    "\n",
    "    user_expectation = ytest.sum()\n",
    "\n",
    "    def query_loss_func(Xquery, theta):\n",
    "        nquery = Xquery.shape[0].value\n",
    "        sum = tf.reduce_sum(tf.sigmoid(Xquery @ theta))\n",
    "        return 1 / nquery * tf.norm(user_expectation - sum)\n",
    "\n",
    "    clf = skLogisticRegression(solver=\"lbfgs\", max_iter=500, random_state=seed).fit(Xtrain, ycrptd)\n",
    "    clff1 = f1_score(ytest, clf.predict(Xtest))\n",
    "    clfrecall = f1_score(ytest, clf.predict(Xtest))\n",
    "    clfprecision = f1_score(ytest, clf.predict(Xtest))\n",
    "\n",
    "    Xquery = Xtest\n",
    "\n",
    "    (theta, delta, logistic_objective), train_logistic_op, influence = create_influence_model(Xtrain, Xquery, ycrptd, query_loss_func)\n",
    "\n",
    "\n",
    "    K = int(sel_crpt.sum() * 2)\n",
    "    vdeltas = np.empty((K, len(Xtrain)))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in tnrange(K, desc=desc):\n",
    "            for _ in EarlyStopTrainer(sess, logistic_objective, max_iter=5000, tol=1e-8):\n",
    "                sess.run(train_logistic_op)\n",
    "\n",
    "            vinfluence, vtheta = sess.run([influence, theta])\n",
    "\n",
    "            i = np.argmax(vinfluence)\n",
    "\n",
    "            sess.run(delta[i].assign([0]))\n",
    "            vdelta = sess.run(delta)\n",
    "\n",
    "            vdeltas[k,:] = vdelta.squeeze()\n",
    "\n",
    "    tdelta = (1 - sel_crpt)\n",
    "\n",
    "    r = Record(EXPERIMENT_NAME)\n",
    "    r.input(EXPERIMENT_DESC)\n",
    "    r.output({\"model_perf\": [clff1, clfprecision, clfrecall], \"deltas\": vdeltas.tolist(), \"tdelta\": tdelta.tolist()})\n",
    "    r.insert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
