{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps, loads\n",
    "from time import time\n",
    "from typing import Any, NamedTuple\n",
    "\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import py_stringmatching as sm\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from tensorflow.losses import sigmoid_cross_entropy\n",
    "from tensorflow.python.ops.parallel_for import jacobian\n",
    "\n",
    "from mlsql.archiver import Record\n",
    "from mlsql.experiments.duti import create_gradient_model, create_dataset, create_influence_model, DogCatConfig\n",
    "from mlsql.tensorflow.problem import LogisticRegression as tfLogisticRegression\n",
    "from mlsql.tensorflow.utils import EarlyStopTrainer\n",
    "\n",
    "from tqdm import tnrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1558545695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupt_type = DogCatConfig.Duti\n",
    "query = \"SELECT COUNT(*) WHERE clf() = 1\"\n",
    "EXPERIMENT_NAME = \"DUTI-Influence-Retrain\"\n",
    "EXPERIMENT_DESC = {\n",
    "    \"seed\": seed,\n",
    "    \"query\": query,\n",
    "    \"dataset\": \"duti\",\n",
    "    \"corrupt_type\": str(corrupt_type),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain, ytrain), (Xtest, ytest), ycrptd, sel_crpt = create_dataset(seed, corrupt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xquery = Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/youngw/.pyenv/versions/3.7.2/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/youngw/.pyenv/versions/3.7.2/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/youngw/.pyenv/versions/3.7.2/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def query_loss_func(Xquery, theta):\n",
    "    nquery = Xquery.shape[0].value\n",
    "    sum = tf.reduce_sum(tf.sigmoid(Xquery @ theta))\n",
    "    return 1 / nquery * tf.norm(ytest.sum() - sum)\n",
    "    \n",
    "(theta, delta, logistic_objective), train_logistic_op, influence = create_influence_model(Xtrain, Xquery, ycrptd, query_loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5c99d47f5f49059e72cb6aa36099e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=54), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K = int(sel_crpt.sum() * 1.5)\n",
    "deletions = []\n",
    "\n",
    "clf = skLogisticRegression(solver=\"lbfgs\", max_iter=500, random_state=seed).fit(Xtrain, ycrptd)\n",
    "clff1 = f1_score(ytest, clf.predict(Xtest))\n",
    "clfrecall = f1_score(ytest, clf.predict(Xtest))\n",
    "clfprecision = f1_score(ytest, clf.predict(Xtest))\n",
    "\n",
    "vdeltas = np.empty((K, len(Xtrain)))\n",
    "deletions = np.empty(K)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for k in tnrange(K):\n",
    "        for _ in EarlyStopTrainer(sess, logistic_objective, max_iter=5000, tol=1e-8):\n",
    "            sess.run(train_logistic_op)\n",
    "\n",
    "        vinfluence, vtheta = sess.run([influence, theta])\n",
    "        \n",
    "        i = np.argmax(vinfluence)\n",
    "        \n",
    "        sess.run(delta[i].assign([0]))\n",
    "        vdelta = sess.run(delta)\n",
    "        \n",
    "        deletions[k] = i\n",
    "        vdeltas[k,:] = vdelta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdelta = (1 - sel_crpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60        36\n",
      "           1       0.80      0.58      0.67        64\n",
      "\n",
      "   micro avg       0.64      0.64      0.64       100\n",
      "   macro avg       0.65      0.66      0.64       100\n",
      "weighted avg       0.69      0.64      0.65       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(tdelta, vdeltas[-1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Record(EXPERIMENT_NAME)\n",
    "r.input(EXPERIMENT_DESC)\n",
    "r.output({\"model_perf\": [clff1, clfprecision, clfrecall], \"deltas\": vdeltas.tolist(), \"tdelta\": tdelta.tolist()})\n",
    "r.insert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249caf88b65545e2a9cfbd0ad4b225f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.Duti]', max=72, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7180e82984e9428da31e8ff790ef372b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.FarLine]', max=20, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e1a6736ebbd42b195db0d589db1ef0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='[DogCatConfig.CloseBoundary]', max=20, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 1558545695\n",
    "EXPERIMENT_NAME = \"DUTI-Influence-Retrain\"\n",
    "query = \"SELECT COUNT(*) WHERE clf() = 1\"\n",
    "\n",
    "for corrupt_type in DogCatConfig:\n",
    "    EXPERIMENT_DESC = {\n",
    "        \"seed\": seed,\n",
    "        \"query\": query,\n",
    "        \"dataset\": \"duti\",\n",
    "        \"corrupt_type\": str(corrupt_type),\n",
    "    }\n",
    "\n",
    "    desc = f\"[{corrupt_type}]\"\n",
    "\n",
    "    (Xtrain, ytrain), (Xtest, ytest), ycrptd, sel_crpt = create_dataset(seed, corrupt_type)\n",
    "\n",
    "    user_expectation = ytest.sum()\n",
    "\n",
    "    def query_loss_func(Xquery, theta):\n",
    "        nquery = Xquery.shape[0].value\n",
    "        sum = tf.reduce_sum(tf.sigmoid(Xquery @ theta))\n",
    "        return 1 / nquery * tf.norm(user_expectation - sum)\n",
    "\n",
    "    clf = skLogisticRegression(solver=\"lbfgs\", max_iter=500, random_state=seed).fit(Xtrain, ycrptd)\n",
    "    clff1 = f1_score(ytest, clf.predict(Xtest))\n",
    "    clfrecall = f1_score(ytest, clf.predict(Xtest))\n",
    "    clfprecision = f1_score(ytest, clf.predict(Xtest))\n",
    "\n",
    "    Xquery = Xtest\n",
    "\n",
    "    (theta, delta, logistic_objective), train_logistic_op, influence = create_influence_model(Xtrain, Xquery, ycrptd, query_loss_func)\n",
    "\n",
    "\n",
    "    K = int(sel_crpt.sum() * 2)\n",
    "    vdeltas = np.empty((K, len(Xtrain)))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in tnrange(K, desc=desc):\n",
    "            for _ in EarlyStopTrainer(sess, logistic_objective, max_iter=5000, tol=1e-8):\n",
    "                sess.run(train_logistic_op)\n",
    "\n",
    "            vinfluence, vtheta = sess.run([influence, theta])\n",
    "\n",
    "            i = np.argmax(vinfluence)\n",
    "\n",
    "            sess.run(delta[i].assign([0]))\n",
    "            vdelta = sess.run(delta)\n",
    "\n",
    "            vdeltas[k,:] = vdelta.squeeze()\n",
    "\n",
    "    tdelta = (1 - sel_crpt)\n",
    "\n",
    "    r = Record(EXPERIMENT_NAME)\n",
    "    r.input(EXPERIMENT_DESC)\n",
    "    r.output({\"model_perf\": [clff1, clfprecision, clfrecall], \"deltas\": vdeltas.tolist(), \"tdelta\": tdelta.tolist()})\n",
    "    r.insert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
