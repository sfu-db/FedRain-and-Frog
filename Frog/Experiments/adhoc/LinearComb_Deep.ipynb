{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "#sys.path.append(\"../../extra-package\")\n",
    "\n",
    "import gurobipy\n",
    "from json import dumps, loads\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score, recall_score)\n",
    "from tqdm import tnrange, trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlsql import InfluenceRanker, SelfLossInfluenceRanker, AutoFixer, ModelManagerLM, LossRanker, TiresiasRanker, multi_ambiguity_count\n",
    "# from mlsql.models import SimpleCNN, LogReg\n",
    "from mlsql.models.nn import SimpleCNN1D, SimpleCNN1D_Linear, MLP, MLP_Linear\n",
    "\n",
    "from mlsql.utils import setdiff1d\n",
    "from processors.adultNoCorr import AdultNoCorrProcessor\n",
    "\n",
    "from itertools import groupby\n",
    "from functools import partial\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "@tf.function\n",
    "def rank_fix(ranker, fixer, n):\n",
    "    rank = ranker.predict()\n",
    "    fixer.fix(rank, n)\n",
    "    return rank\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rankit(ranker):\n",
    "    rank = ranker.predict()\n",
    "    return rank\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def fixit(fixer, rank, n):\n",
    "    fixer.fix(rank, n)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train(manager):\n",
    "    manager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26048,)\n",
      "(26048, 17)\n",
      "tf.Tensor(nan, shape=(), dtype=float32)\n",
      "17\n",
      "MLP\n",
      "On Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.76      1.00      0.86     19788\n",
      "         1.0       0.00      0.00      0.00      6260\n",
      "\n",
      "    accuracy                           0.76     26048\n",
      "   macro avg       0.38      0.50      0.43     26048\n",
      "weighted avg       0.58      0.76      0.66     26048\n",
      "\n",
      "On Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.76      1.00      0.86      2468\n",
      "         1.0       0.00      0.00      0.00       788\n",
      "\n",
      "    accuracy                           0.76      3256\n",
      "   macro avg       0.38      0.50      0.43      3256\n",
      "weighted avg       0.57      0.76      0.65      3256\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yejia/anaconda3/envs/run_fl/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "seed = 2987429\n",
    "proc = AdultNoCorrProcessor(seed)\n",
    "print(proc.ytrain.shape)\n",
    "print(proc.Xtrain.shape)\n",
    "\n",
    "# model = SimpleCNN1D(proc, 1, input_shape=[proc.Xtrain.shape[1], 1])\n",
    "model = MLP(proc, 1)\n",
    "manager0 = ModelManagerLM(proc.X_Atrain, proc.X_Btrain, proc.ytrain, model)\n",
    "manager0.fit(print_value=True)\n",
    "# print(\"SimpleCNN1D\")\n",
    "print(\"MLP\")\n",
    "print(\"On Training\\n\", classification_report(proc.ytrain.numpy(), manager0.predict(proc.X_Atrain, proc.X_Btrain).numpy()))\n",
    "print(\"On Testing\\n\", classification_report(proc.ytest.numpy(), manager0.predict(proc.X_Atest, proc.X_Btest).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2600\n",
    "corrsel = tf.cast(tf.ones(proc.ytrain.shape[0]), dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange, trange\n",
    "# model_plus = SimpleCNN1D(proc, 1, input_shape=[proc.Xtrain.shape[1], 1])\n",
    "model_plus = MLP(proc, 1)\n",
    "manager = ModelManagerLM(proc.X_Atrain, proc.X_Btrain, proc.ytrain, model_plus)\n",
    "manager.model.set_weights(manager0.model.get_weights())\n",
    "manager.delta = tf.Variable(manager0.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "_, AQ, _, _ = proc.complain(manager)\n",
    "f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager.fit()\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "    _, AQ, _, _ = proc.complain(manager)\n",
    "    f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "    AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "\n",
    "df_rain = pd.DataFrame({\n",
    "    \"Complain\": np.array(AQs),\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": [1] + list(range(step_size, K + step_size, step_size)),\n",
    "    \"Method\": np.repeat(\"Rain\", len(AQs)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain])).mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_del = set(fixer.deletions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearComb\n",
    "\n",
    "# model = SimpleCNN1D_Linear(proc, 1, input_shape_a=[proc.X_Atrain.shape[1], 1], input_shape_b=[proc.X_Btrain.shape[1], 1])\n",
    "model = MLP_Linear(proc, 1)\n",
    "manager1 = ModelManagerLM(proc.X_Atrain, proc.X_Btrain, proc.ytrain, model)\n",
    "manager1.fit(print_value=True, max_iter=2000, tol=1e-6)\n",
    "# print(\"SimpleCNN1D_Linear\")\n",
    "print(\"MLP_Linear\")\n",
    "print(\"On Training\\n\", classification_report(proc.ytrain.numpy(), manager1.predict(proc.X_Atrain, proc.X_Btrain).numpy()))\n",
    "print(\"On Testing\\n\", classification_report(proc.ytest.numpy(), manager1.predict(proc.X_Atest, proc.X_Btest).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_plus = SimpleCNN1D_Linear(proc, 1, input_shape_a=[proc.X_Atrain.shape[1], 1], input_shape_b=[proc.X_Btrain.shape[1], 1])\n",
    "model_plus = MLP_Linear(proc, 1)\n",
    "manager = ModelManagerLM(proc.X_Atrain, proc.X_Btrain, proc.ytrain, model_plus)\n",
    "manager.model.set_weights(manager1.model.get_weights())\n",
    "manager.delta = tf.Variable(manager1.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_lcomb = 0\n",
    "model_time_lcomb = 0\n",
    "_, AQ, _, _ = proc.complain(manager)\n",
    "f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "#     train(manager)\n",
    "    manager.fit(print_value=True, tol=1e-6)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_lcomb += middle - start\n",
    "    model_time_lcomb += end - middle\n",
    "\n",
    "    _, AQ, _, _ = proc.complain(manager)\n",
    "    f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "    AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_lcomb)\n",
    "print(\"Model_time:\", model_time_lcomb)\n",
    "\n",
    "df_lcomb = pd.DataFrame({\n",
    "    \"Complain\": np.array(AQs),\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": [1] + list(range(step_size, K + step_size, step_size)),\n",
    "    \"Method\": np.repeat(\"Lcomb\", len(AQs)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_lcomb])).mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.concat([df_rain, df_lcomb]), title=\"Complain of query data vs. K, AC=0, MLP\").mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.concat([df_rain, df_lcomb]), title=\"F1 score of test data vs. K, MLP\",).mark_line().encode(\n",
    "    alt.Y('F1',\n",
    "        scale=alt.Scale(domain=(0.75, 0.85))\n",
    "    ),\n",
    "    x = \"K\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcomb_del = set(fixer.deletions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rain_del.intersection(lcomb_del))/2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (run_fl)",
   "language": "python",
   "name": "run_fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
