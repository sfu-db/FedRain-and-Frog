{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import gurobipy\n",
    "from json import dumps, loads\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score, recall_score)\n",
    "from tqdm import tnrange, trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlsql.influence import InfluenceRanker\n",
    "from mlsql.fixer import AutoFixer\n",
    "from mlsql.manager import ModelManagerLM\n",
    "from mlsql.manager_test import ModelManagerTest\n",
    "\n",
    "from models.simple_cnn import SimpleCNN\n",
    "from models.logreg import LogReg\n",
    "from models.linear_comb import LinearComb\n",
    "from models.linear_comb_test import LinearCombTest\n",
    "from processors.diabetes import DiabetesProcessor\n",
    "from processors.diabetes_corruption import DiabetesCorrProcessor\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import time\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def rank_fix(ranker, fixer, n):\n",
    "    rank = ranker.predict()\n",
    "    fixer.fix(rank, n)\n",
    "    return rank\n",
    "\n",
    "@tf.function\n",
    "def rankit(ranker):\n",
    "    rank = ranker.predict()\n",
    "    return rank\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def fixit(fixer, rank, n):\n",
    "    fixer.fix(rank, n)\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train(manager):\n",
    "    manager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = DiabetesCorrProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rain\n",
    "model = LogReg(1)\n",
    "manager0 = ModelManagerLM(proc.x_train, proc.y_corr, model, 256)\n",
    "start = time.time()\n",
    "manager0.fit(print_value=True, tol=1e-7, max_iter=10000)\n",
    "print(time.time() - start)\n",
    "manager0.report(proc.x_train, proc.y_corr, proc.x_test, proc.y_test)\n",
    "# manager0.report(proc.x_train, proc.y_corr, proc.x_query, proc.y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print number of corruptions\n",
    "corrsel = proc.corrsel\n",
    "K = len(list(np.where(corrsel)[0]))\n",
    "print(len(list(np.where(corrsel)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rain Debug\n",
    "from tqdm.notebook import tnrange, trange\n",
    "manager = ModelManagerLM(proc.x_train, proc.y_corr, LogReg(1), 256)\n",
    "manager.model.set_weights(manager0.model.get_weights())\n",
    "manager.delta = tf.Variable(manager0.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "# from mlsql.loss_ranker import LossRanker\n",
    "# ranker = LossRanker(manager=manager_test)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "# AQ = proc.complain(manager).AQ\n",
    "f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "# f1 = f1_score(proc.y_query.numpy(), manager.model.predict(proc.x_query).numpy(), average='weighted')\n",
    "# AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager.fit(max_iter=5000, tol=1e-7, print_value=True)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "#     AQ = proc.complain(manager).AQ\n",
    "    f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "#     f1 = f1_score(proc.y_query.numpy(), manager.model.predict(proc.x_query).numpy(), average='weighted')\n",
    "#     AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "AC = proc.complain(manager).AC\n",
    "\n",
    "df_rain_test = pd.DataFrame({\n",
    "#     \"Complain\": np.array(AQs) - AC,\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": list(range(0, K, step_size)) + [K],\n",
    "    \"Method\": np.repeat(\"Rain\", len(weighted_f1)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain_test])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain_test.shape[0], grid=False)),\n",
    "    alt.Y(\"Complain:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.Chart(pd.concat([df_rain_test])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain_test.shape[0], grid=False)),\n",
    "    alt.Y(\"F1:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = DiabetesCorrProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frog Model\n",
    "model = LinearCombTest(1)\n",
    "manager_test0 = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, model, 256)\n",
    "start = time.time()\n",
    "manager_test0.fit(print_value=True, tol=1e-8, lr=0.1, max_iter=20000)\n",
    "print(time.time() - start)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_test, proc.x_b_test, proc.y_test)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_query, proc.x_b_query, proc.y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrsel = proc.corrsel\n",
    "K = len(list(np.where(corrsel)[0]))\n",
    "print(len(list(np.where(corrsel)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Frog Debug\n",
    "manager_test = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, LinearCombTest(1), 256)\n",
    "manager_test.model.set_weights(manager_test0.model.get_weights())\n",
    "manager_test.delta = tf.Variable(manager_test0.delta.value(), name=\"delta\")\n",
    "from mlsql.loss_ranker import LossRanker\n",
    "# ranker = LossRanker(manager=manager_test)\n",
    "ranker = InfluenceRanker(manager=manager_test, on=proc.test_complain)\n",
    "fixer = AutoFixer(manager_test, proc.corrsel, K)\n",
    "\n",
    "# AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "# AQ = proc.test_complain(manager_test).AQ\n",
    "f1 = f1_score(proc.y_test.numpy(), manager_test.model.predict(proc.x_a_test, proc.x_b_test).numpy(), average='weighted')\n",
    "# f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "# AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager_test.fit(max_iter=10000, tol=1e-8, print_value=True)\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "#     AQ = proc.test_complain(manager_test).AQ\n",
    "    f1 = f1_score(proc.y_test.numpy(), manager_test.model.predict(proc.x_a_test, proc.x_b_test).numpy(), average='weighted')\n",
    "#     f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "#     AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "# AC = proc.test_complain(manager_test).AC\n",
    "\n",
    "\n",
    "alt.Chart(pd.concat([df_rain_test])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain_test.shape[0], grid=False)),\n",
    "    alt.Y(\"F1:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer.deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(proc.corrsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixer.recall_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = DiabetesCorrProcessor()\n",
    "model = LinearCombTest(1)\n",
    "manager_test0 = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, model, 256)\n",
    "start = time.time()\n",
    "manager_test0.fit(print_value=True, tol=1e-8, lr=0.1, max_iter=20000)\n",
    "print(time.time() - start)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_test, proc.x_b_test, proc.y_test)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_query, proc.x_b_query, proc.y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Ranker\n",
    "manager_test = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, LinearCombTest(1), 256)\n",
    "manager_test.model.set_weights(manager_test0.model.get_weights())\n",
    "manager_test.delta = tf.Variable(manager_test0.delta.value(), name=\"delta\")\n",
    "from mlsql.loss_ranker import LossRanker\n",
    "ranker = LossRanker(manager=manager_test)\n",
    "# ranker = InfluenceRanker(manager=manager_test, on=proc.test_complain)\n",
    "fixer = AutoFixer(manager_test, proc.corrsel, K)\n",
    "\n",
    "# AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "# AQ = proc.test_complain(manager_test).AQ\n",
    "f1 = f1_score(proc.y_test.numpy(), manager_test.model.predict(proc.x_a_test, proc.x_b_test).numpy(), average='weighted')\n",
    "# f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "# AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager_test.fit(max_iter=10000, tol=1e-8, print_value=True)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "#     AQ = proc.test_complain(manager_test).AQ\n",
    "    f1 = f1_score(proc.y_test.numpy(), manager_test.model.predict(proc.x_a_test, proc.x_b_test).numpy(), average='weighted')\n",
    "#     f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "#     AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "# AC = proc.test_complain(manager_test).AC\n",
    "\n",
    "df_rain_test = pd.DataFrame({\n",
    "#     \"Complain\": np.array(AQs) - AC,\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": list(range(0, K, step_size)) + [K],\n",
    "    \"Method\": np.repeat(\"Rain\", len(weighted_f1)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain_test])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain_test.shape[0], grid=False)),\n",
    "    alt.Y(\"F1:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
