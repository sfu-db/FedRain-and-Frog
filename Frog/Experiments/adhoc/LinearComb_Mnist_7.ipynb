{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import gurobipy\n",
    "from json import dumps, loads\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score, recall_score)\n",
    "from tqdm import tnrange, trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlsql.influence import InfluenceRanker\n",
    "from mlsql.fixer import AutoFixer\n",
    "from mlsql.manager import ModelManagerLM\n",
    "from mlsql.manager_test import ModelManagerTest\n",
    "\n",
    "from models.simple_cnn import SimpleCNN\n",
    "from models.logreg import LogReg\n",
    "from models.linear_comb import LinearComb\n",
    "from models.linear_comb_test import LinearCombTest\n",
    "from processors.mnistbinary_7 import MnistBinaryProcessor\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)\n",
    "\n",
    "import time\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def rank_fix(ranker, fixer, n):\n",
    "    rank = ranker.predict()\n",
    "    fixer.fix(rank, n)\n",
    "    return rank\n",
    "\n",
    "@tf.function\n",
    "def rankit(ranker):\n",
    "    rank = ranker.predict()\n",
    "    return rank\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def fixit(fixer, rank, n):\n",
    "    fixer.fix(rank, n)\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train(manager):\n",
    "    manager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = MnistBinaryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD loss: tf.Tensor(0.367625, shape=(), dtype=float32)\n",
      "SGD steps: 356\n",
      "40.59802484512329\n",
      "Model name: LogReg\n",
      "On Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92     45776\n",
      "         1.0       0.22      0.00      0.00      8224\n",
      "\n",
      "    accuracy                           0.85     54000\n",
      "   macro avg       0.54      0.50      0.46     54000\n",
      "weighted avg       0.75      0.85      0.78     54000\n",
      "\n",
      "On Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      1.00      0.66      4926\n",
      "         1.0       1.00      0.00      0.01      5074\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.75      0.50      0.34     10000\n",
      "weighted avg       0.75      0.50      0.33     10000\n",
      "\n",
      "Model name: LogReg\n",
      "On Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92     45776\n",
      "         1.0       0.22      0.00      0.00      8224\n",
      "\n",
      "    accuracy                           0.85     54000\n",
      "   macro avg       0.54      0.50      0.46     54000\n",
      "weighted avg       0.75      0.85      0.78     54000\n",
      "\n",
      "On Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65      2905\n",
      "         1.0       1.00      0.00      0.01      3095\n",
      "\n",
      "    accuracy                           0.49      6000\n",
      "   macro avg       0.74      0.50      0.33      6000\n",
      "weighted avg       0.75      0.49      0.32      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogReg(1)\n",
    "manager0 = ModelManagerLM(proc.x_train, proc.y_corr, model, 256)\n",
    "start = time.time()\n",
    "manager0.fit(print_value=True, tol=1e-5, lr=0.1, max_iter=2000)\n",
    "print(time.time() - start)\n",
    "manager0.report(proc.x_train, proc.y_corr, proc.x_test, proc.y_test)\n",
    "manager0.report(proc.x_train, proc.y_corr, proc.x_query, proc.y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19189\n"
     ]
    }
   ],
   "source": [
    "K = 19189\n",
    "corrsel = proc.corrsel\n",
    "print(len(list(np.where(corrsel)[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8c5c17aade4390af8d53605ba02f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1919 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD loss: tf.Tensor(0.36678332, shape=(), dtype=float32)\n",
      "SGD steps: 9\n",
      "SGD loss: tf.Tensor(0.36600056, shape=(), dtype=float32)\n",
      "SGD steps: 9\n",
      "SGD loss: tf.Tensor(0.365266, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.3645624, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.3638785, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.36321157, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.36256206, shape=(), dtype=float32)\n",
      "SGD steps: 7\n",
      "SGD loss: tf.Tensor(0.36190385, shape=(), dtype=float32)\n",
      "SGD steps: 9\n",
      "SGD loss: tf.Tensor(0.36130732, shape=(), dtype=float32)\n",
      "SGD steps: 4\n",
      "SGD loss: tf.Tensor(0.36068422, shape=(), dtype=float32)\n",
      "SGD steps: 7\n",
      "SGD loss: tf.Tensor(0.36009023, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.3594628, shape=(), dtype=float32)\n",
      "SGD steps: 9\n",
      "SGD loss: tf.Tensor(0.3588685, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35828772, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.357701, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35711828, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35655054, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.35595503, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.35540262, shape=(), dtype=float32)\n",
      "SGD steps: 4\n",
      "SGD loss: tf.Tensor(0.35483125, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35426146, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35367107, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.35311207, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.35254616, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.35199413, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.35144714, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.3508816, shape=(), dtype=float32)\n",
      "SGD steps: 7\n",
      "SGD loss: tf.Tensor(0.3503064, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34975338, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.34921148, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.34864116, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34810176, shape=(), dtype=float32)\n",
      "SGD steps: 5\n",
      "SGD loss: tf.Tensor(0.3475321, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34696367, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34640595, shape=(), dtype=float32)\n",
      "SGD steps: 7\n",
      "SGD loss: tf.Tensor(0.34583822, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34526968, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34470212, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.344134, shape=(), dtype=float32)\n",
      "SGD steps: 8\n",
      "SGD loss: tf.Tensor(0.34358755, shape=(), dtype=float32)\n",
      "SGD steps: 6\n",
      "SGD loss: tf.Tensor(0.34303197, shape=(), dtype=float32)\n",
      "SGD steps: 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ede10b437e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnfix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mmiddle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FederatedRain/Experiments/mlsql/manager.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, max_iter, print_value, tol, lr)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m       \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_remaining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mlast_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;31m#       print(last_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FederatedRain/Experiments/mlsql/manager.py\u001b[0m in \u001b[0;36msgd_fn\u001b[0;34m(self, data, labels, last_loss, opt, tol)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mcont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstFirstOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_MatMulGradAgainstSecondOnly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGradAgainstSecondOnly\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1660\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5619\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5620\u001b[0m         \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5621\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5622\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5623\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tnrange, trange\n",
    "manager = ModelManagerLM(proc.x_train, proc.y_corr, LogReg(1), 256)\n",
    "manager.model.set_weights(manager0.model.get_weights())\n",
    "manager.delta = tf.Variable(manager0.delta.value(), name=\"delta\")\n",
    "from mlsql.loss_ranker import LossRanker\n",
    "ranker = LossRanker(manager=manager)\n",
    "# ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "# AQ = proc.complain(manager).AQ\n",
    "# f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "f1 = f1_score(proc.y_query.numpy(), manager.model.predict(proc.x_query).numpy(), average='weighted')\n",
    "# AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager.fit(max_iter=1000, print_value=True, lr=0.1, tol=1e-5)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "#     AQ = proc.complain(manager).AQ\n",
    "#     f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "    f1 = f1_score(proc.y_query.numpy(), manager.model.predict(proc.x_query).numpy(), average='weighted')\n",
    "#     AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "# AC = proc.complain(manager).AC\n",
    "\n",
    "df_rain = pd.DataFrame({\n",
    "#     \"Complain\": np.array(AQs) - AC,\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": list(range(0, K, step_size)) + [K],\n",
    "    \"Method\": np.repeat(\"Rain\", len(weighted_f1)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain.shape[0], grid=False)),\n",
    "    alt.Y(\"F1:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.50586273, 0.50591485,\n",
       "       0.50596696])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixer.recall_k()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: LogReg\n",
      "On Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92     45776\n",
      "         1.0       0.22      0.00      0.00      8224\n",
      "\n",
      "    accuracy                           0.85     54000\n",
      "   macro avg       0.54      0.50      0.46     54000\n",
      "weighted avg       0.75      0.85      0.78     54000\n",
      "\n",
      "On Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      1.00      0.66      4926\n",
      "         1.0       1.00      0.00      0.01      5074\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.75      0.50      0.34     10000\n",
      "weighted avg       0.75      0.50      0.33     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "manager0.report(proc.x_train, proc.y_corr, proc.x_test, proc.y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01443535, 0.04049195, 0.06628798,\n",
       "       0.09218823, 0.11782792, 0.14305071, 0.1683256 , 0.19323571,\n",
       "       0.21804159, 0.24201365, 0.26614206, 0.28990568, 0.31215801,\n",
       "       0.33540049, 0.35822607, 0.38094742, 0.40179269, 0.42169993,\n",
       "       0.44150294, 0.4610975 , 0.48079629, 0.49934859, 0.50596696])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((fixer.recall_k()[0::500], fixer.recall_k()[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearCombTest\n",
    "model = LinearCombTest(1)\n",
    "manager_test0 = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, model, 256)\n",
    "start = time.time()\n",
    "manager_test0.fit(print_value=True, tol=1e-9, lr=0.1, max_iter=50000)\n",
    "print(time.time() - start)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_test, proc.x_b_test, proc.y_test)\n",
    "manager_test0.report(proc.x_a_train, proc.x_b_train, proc.y_corr, proc.x_a_query, proc.x_b_query, proc.y_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_test = ModelManagerTest(proc.x_a_train, proc.x_b_train, proc.y_corr, LinearCombTest(1), 256)\n",
    "manager_test.model.set_weights(manager_test0.model.get_weights())\n",
    "manager_test.delta = tf.Variable(manager_test0.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager_test, on=proc.test_complain)\n",
    "fixer = AutoFixer(manager_test, proc.corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "AQ = proc.test_complain(manager_test).AQ\n",
    "# f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 19189\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    manager_test.fit(max_iter=5000, tol=1e-8, lr=0.1, print_value=True)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "    AQ = proc.test_complain(manager_test).AQ\n",
    "#     f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "    f1 = f1_score(proc.y_query.numpy(), manager_test.model.predict(proc.x_a_query, proc.x_b_query).numpy(), average='weighted')\n",
    "    AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "AC = proc.test_complain(manager_test).AC\n",
    "\n",
    "df_rain_test = pd.DataFrame({\n",
    "    \"Complain\": np.array(AQs) - AC,\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": list(range(0, K, step_size)) + [K],\n",
    "    \"Method\": np.repeat(\"Rain\", len(AQs)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain_test])).mark_line().encode(\n",
    "    alt.X('K:Q', axis=alt.Axis(tickCount=df_rain_test.shape[0], grid=False)),\n",
    "    alt.Y(\"Complain:Q\"),\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((fixer.recall_k()[0::1000], fixer.recall_k()[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
