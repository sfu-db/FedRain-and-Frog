{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import gurobipy\n",
    "from json import dumps, loads\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as skLogisticRegression\n",
    "from sklearn.metrics import (classification_report, f1_score, precision_score, recall_score)\n",
    "from tqdm import tnrange, trange\n",
    "import tensorflow as tf\n",
    "\n",
    "from mlsql.influence import InfluenceRanker\n",
    "from mlsql.fixer import AutoFixer\n",
    "from mlsql.manager import ModelManagerLM\n",
    "\n",
    "from models.simple_cnn import SimpleCNN\n",
    "from models.logreg import LogReg\n",
    "from models.linear_comb import LinearComb\n",
    "from processors.adultNoCorr import AdultNoCorrProcessor\n",
    "\n",
    "from itertools import groupby\n",
    "from functools import partial\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "@tf.function\n",
    "def rank_fix(ranker, fixer, n):\n",
    "    rank = ranker.predict()\n",
    "    fixer.fix(rank, n)\n",
    "    return rank\n",
    "\n",
    "@tf.function\n",
    "def rankit(ranker):\n",
    "    rank = ranker.predict()\n",
    "    return rank\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def fixit(fixer, rank, n):\n",
    "    fixer.fix(rank, n)\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "def train(manager):\n",
    "    manager.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD loss: tf.Tensor(0.39970687, shape=(), dtype=float32)\n",
      "SGD steps: 499\n",
      "3.61708927154541\n",
      "Model name: LogReg\n",
      "On Training\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.93      0.88     19751\n",
      "         1.0       0.68      0.43      0.53      6297\n",
      "\n",
      "    accuracy                           0.81     26048\n",
      "   macro avg       0.76      0.68      0.70     26048\n",
      "weighted avg       0.80      0.81      0.80     26048\n",
      "\n",
      "On Testing\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.88      2462\n",
      "         1.0       0.69      0.44      0.54       794\n",
      "\n",
      "    accuracy                           0.82      3256\n",
      "   macro avg       0.76      0.69      0.71      3256\n",
      "weighted avg       0.80      0.82      0.80      3256\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "proc = AdultNoCorrProcessor()\n",
    "model = LogReg(1)\n",
    "manager0 = ModelManagerLM(proc.x_train, proc.y_train, model, 1024)\n",
    "start = time.time()\n",
    "manager0.fit(print_value=True)\n",
    "print(time.time() - start)\n",
    "manager0.report(proc.x_train, proc.y_train, proc.x_test, proc.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsql.lc_protocol import fit as lc_fit\n",
    "model_a = LinearComb(1)\n",
    "manager_a = ModelManagerLM(proc.x_a_train, proc.y_train, model_a)\n",
    "model_b = LinearComb(1)\n",
    "manager_b = ModelManagerLM(proc.x_b_train, proc.y_train, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.894684553146362\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for iteration in range(1000):\n",
    "    evaluate_a = manager_a.master_evaluate() # c1f1-y\n",
    "    egrads_a = manager_a.egrads() # c1\n",
    "    evaluate_b = manager_b.slave_evaluate() # c2f2\n",
    "    egrads_b = manager_b.egrads() # c2\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate_a = manager_a.master_evaluate() # c1f1-y\n",
    "# egrads_a = manager_a.egrads() # c1\n",
    "# evaluate_b = manager_b.slave_evaluate() # c2f2\n",
    "# egrads_b = manager_b.egrads() # c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245.4406714439392\n"
     ]
    }
   ],
   "source": [
    "# 2048\n",
    "# *1000*26\n",
    "start = time.time()\n",
    "eval_a = evaluate_a.numpy()\n",
    "enc_a_eval_a = manager_a.encrypt(eval_a[:1000]) # [c1f1-y]_a\n",
    "eval_b = evaluate_b.numpy()\n",
    "enc_b_eval_b = manager_b.encrypt(eval_b[:1000]) # [c2f2]_b\n",
    "enc_a_grads_b = (enc_a_eval_a[:1000].reshape(-1, 1) + eval_b[:1000])\n",
    "enc_a_grads_b = (egrads_b.numpy()[:1000] * enc_a_grads_b).mean(axis=0)\n",
    "manager_a.decrypt(enc_a_grads_b)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.96947455406189\n"
     ]
    }
   ],
   "source": [
    "# 1024\n",
    "# *1000*26\n",
    "start = time.time()\n",
    "eval_a = evaluate_a.numpy()\n",
    "enc_a_eval_a = manager_a.encrypt(eval_a[:1000]) # [c1f1-y]_a\n",
    "eval_b = evaluate_b.numpy()\n",
    "enc_b_eval_b = manager_b.encrypt(eval_b[:1000]) # [c2f2]_b\n",
    "enc_a_grads_b = (enc_a_eval_a[:1000].reshape(-1, 1) + eval_b[:1000])\n",
    "enc_a_grads_b = (egrads_b.numpy()[:1000] * enc_a_grads_b).mean(axis=0)\n",
    "manager_a.decrypt(enc_a_grads_b)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.94075036048889\n"
     ]
    }
   ],
   "source": [
    "# 512\n",
    "# *100*26\n",
    "start = time.time()\n",
    "eval_a = evaluate_a.numpy()\n",
    "enc_a_eval_a = manager_a.encrypt(eval_a[:10000]) # [c1f1-y]_a\n",
    "eval_b = evaluate_b.numpy()\n",
    "enc_b_eval_b = manager_b.encrypt(eval_b[:10000]) # [c2f2]_b\n",
    "enc_a_grads_b = (enc_a_eval_a[:10000].reshape(-1, 1) + eval_b[:10000])\n",
    "enc_a_grads_b = (egrads_b.numpy()[:10000] * enc_a_grads_b).mean(axis=0)\n",
    "manager_a.decrypt(enc_a_grads_b)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.684959411621094\n"
     ]
    }
   ],
   "source": [
    "# 256\n",
    "# *100*26\n",
    "start = time.time()\n",
    "eval_a = evaluate_a.numpy()\n",
    "enc_a_eval_a = manager_a.encrypt(eval_a[:10000]) # [c1f1-y]_a\n",
    "eval_b = evaluate_b.numpy()\n",
    "enc_b_eval_b = manager_b.encrypt(eval_b[:10000]) # [c2f2]_b\n",
    "enc_a_grads_b = (enc_a_eval_a[:10000].reshape(-1, 1) + eval_b[:10000])\n",
    "enc_a_grads_b = (egrads_b.numpy()[:10000] * enc_a_grads_b).mean(axis=0)\n",
    "manager_a.decrypt(enc_a_grads_b)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dead810bb7c44be6ae66b801ee7a4b07\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dead810bb7c44be6ae66b801ee7a4b07\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dead810bb7c44be6ae66b801ee7a4b07\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-ead018d11810b4a7a80a03b9f0765187\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"Method\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"n_bit\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"Time Cost (h)\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-ead018d11810b4a7a80a03b9f0765187\": [{\"n_bit\": 2048, \"Time Cost (h)\": 1772.622222222222, \"Method\": \" Training Encryption\"}, {\"n_bit\": 1025, \"Time Cost (h)\": 266.93333333333334, \"Method\": \" Training Encryption\"}, {\"n_bit\": 512, \"Time Cost (h)\": 46.178888888888885, \"Method\": \" Training Encryption\"}, {\"n_bit\": 256, \"Time Cost (h)\": 12.768888888888888, \"Method\": \" Training Encryption\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc = pd.DataFrame({\n",
    "    \"n_bit\": [2048, 1025, 512, 256],\n",
    "    \"Time Cost (h)\": [245.44*1000*26/60/60, 36.96*1000*26/60/60, 63.94*100*26/60/60, 17.68*100*26/60/60],\n",
    "    \"Method\": np.repeat(\" Training Encryption\", 4),\n",
    "})\n",
    "alt.Chart(pd.concat([df_fuck])).mark_line().encode(\n",
    "    x = \"n_bit\",\n",
    "    y = \"Time Cost (h)\",\n",
    "    color = \"Method\"\n",
    ")\n",
    "# n_bit=np.log2([2048, 1025, 512, 256])\n",
    "\n",
    "# total_time_cost=[245.44*1000*26/60/60, 36.96*1000*26/60/60, 63.94*100*26/60/60, 17.68*100*26/60/60]\n",
    "# plt.xlabel('log2(n_bit)')\n",
    "# plt.ylabel('time cost (hrs)')\n",
    "# plt.plot(n_bit, total_time_cost, 'bo--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_bit</th>\n",
       "      <th>Time Cost (h)</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2048</td>\n",
       "      <td>1772.622222</td>\n",
       "      <td>Training Encryption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1025</td>\n",
       "      <td>266.933333</td>\n",
       "      <td>Training Encryption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>46.178889</td>\n",
       "      <td>Training Encryption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>12.768889</td>\n",
       "      <td>Training Encryption</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_bit  Time Cost (h)                Method\n",
       "0   2048    1772.622222   Training Encryption\n",
       "1   1025     266.933333   Training Encryption\n",
       "2    512      46.178889   Training Encryption\n",
       "3    256      12.768889   Training Encryption"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlsql.lc_protocol import fit as lc_fit\n",
    "model_a = LinearComb(1)\n",
    "manager_a = ModelManagerLM(proc.x_a_train, proc.y_train, model_a)\n",
    "model_b = LinearComb(1)\n",
    "manager_b = ModelManagerLM(proc.x_b_train, proc.y_train, model_b)\n",
    "lc_fit(manager_a, manager_b, max_iter=1, print_value=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2600\n",
    "corrsel = tf.cast(tf.ones(proc.y_train.shape[0]), dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tnrange, trange\n",
    "manager = ModelManagerLM(proc.x_train, proc.y_train, LogReg(1))\n",
    "manager.model.set_weights(manager0.model.get_weights())\n",
    "manager.delta = tf.Variable(manager0.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_rain = 0\n",
    "model_time_rain = 0\n",
    "_, AQ, _, _ = proc.complain(manager)\n",
    "f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "    train(manager)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_rain += middle - start\n",
    "    model_time_rain += end - middle\n",
    "\n",
    "    _, AQ, _, _ = proc.complain(manager)\n",
    "    f1 = f1_score(proc.y_test.numpy(), manager.model.predict(proc.x_test).numpy(), average='weighted')\n",
    "    AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_rain)\n",
    "print(\"Model_time:\", model_time_rain)\n",
    "\n",
    "df_rain = pd.DataFrame({\n",
    "    \"Complain\": np.array(AQs),\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": [1] + list(range(step_size, K + step_size, step_size)),\n",
    "    \"Method\": np.repeat(\"Rain\", len(AQs)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_rain])).mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearComb\n",
    "from mlsql.managerlm_new import ModelManagerLM\n",
    "from mlsql.models.linear_comb_new import LinearComb\n",
    "manager1 = ModelManagerLM(proc.X_Atrain, proc.ytrain, LinearComb(proc, 1))\n",
    "manager1.fit(print_value=True, max_iter=2000, tol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LinearComb\")\n",
    "print(\"On Training\\n\", classification_report(proc.ytrain.numpy(), manager1.predict(proc.X_Atrain).numpy()))\n",
    "print(\"On Testing\\n\", classification_report(proc.ytest.numpy(), manager1.predict(proc.X_Atest).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = ModelManagerLM(proc.X_Atrain, proc.X_Btrain, proc.ytrain, LinearComb(proc, 1))\n",
    "manager.model.set_weights(manager1.model.get_weights())\n",
    "manager.delta = tf.Variable(manager1.delta.value(), name=\"delta\")\n",
    "ranker = InfluenceRanker(manager=manager, on=proc.complain)\n",
    "fixer = AutoFixer(manager, corrsel, K)\n",
    "\n",
    "AQs = []\n",
    "weighted_f1 = []\n",
    "rank_list = []\n",
    "rank_time_lcomb = 0\n",
    "model_time_lcomb = 0\n",
    "_, AQ, _, _ = proc.complain(manager)\n",
    "f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "AQs.append(float(AQ))\n",
    "weighted_f1.append(f1)\n",
    "\n",
    "step_size = 10\n",
    "rain_k = int(np.ceil(K / step_size))\n",
    "for k in trange(0, rain_k):\n",
    "    nfix = min(step_size, K - step_size * k)\n",
    "    assert nfix > 0\n",
    "\n",
    "    start = time.time()\n",
    "    rank = rank_fix(ranker, fixer, nfix)\n",
    "    middle = time.time()\n",
    "#     train(manager)\n",
    "    manager.fit(tol=1e-6)\n",
    "    end = time.time()\n",
    "    \n",
    "    rank_list.append(rank.numpy())\n",
    "    rank_time_lcomb += middle - start\n",
    "    model_time_lcomb += end - middle\n",
    "\n",
    "    _, AQ, _, _ = proc.complain(manager)\n",
    "    f1 = f1_score(proc.ytest.numpy(), manager.predict(proc.X_Atest, proc.X_Btest).numpy(), average='weighted')\n",
    "    AQs.append(float(AQ))\n",
    "    weighted_f1.append(f1)\n",
    "\n",
    "print(\"Rank_time:\", rank_time_lcomb)\n",
    "print(\"Model_time:\", model_time_lcomb)\n",
    "\n",
    "df_lcomb = pd.DataFrame({\n",
    "    \"Complain\": np.array(AQs),\n",
    "    \"F1\": np.array(weighted_f1),\n",
    "    \"K\": [1] + list(range(step_size, K + step_size, step_size)),\n",
    "    \"Method\": np.repeat(\"Lcomb\", len(AQs)),\n",
    "})\n",
    "alt.Chart(pd.concat([df_lcomb])).mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.concat([df_rain, df_lcomb]), title=\"Complain of query data vs. K, AC=0\").mark_line().encode(\n",
    "    x = \"K\",\n",
    "    y = \"Complain\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(pd.concat([df_rain, df_lcomb]), title=\"F1 score of test data vs. K\",).mark_line().encode(\n",
    "    alt.Y('F1',\n",
    "        scale=alt.Scale(domain=(0.75, 0.85))\n",
    "    ),\n",
    "    x = \"K\",\n",
    "    color = \"Method\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcomb_del = set(fixer.deletions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_del = set(fixer.deletions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rain_del.intersection(lcomb_del))/2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rain_del.intersection(lcomb_del))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
